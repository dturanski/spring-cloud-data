name: Create TMC cluster and Install SCDF helm
on:
  workflow_dispatch:
    inputs:
      k8s:
        description: 'aws k8s version'
        required: true
        default: '1.19.4-1-amazon2'
      broker:
        required: true
        default: rabbit

jobs:
  test:
    runs-on: ubuntu-latest

    steps:
      - name: Extract Inputs
        env:
          INPUT_K8S: ${{ github.event.inputs.k8s }}
          INPUT_BROKER: ${{ github.event.inputs.broker }}
        run: |
          echo K8S=${INPUT_K8S:-1.19.4-1-amazon2} >> $GITHUB_ENV
          case "$INPUT_BROKER" in
                  rabbit)
                      echo "RABBIT_ENABLED=true" >> $GITHUB_ENV
                      echo "KAFKA_ENABLED=false" >> $GITHUB_ENV
                      ;;

                  kafka)
                      echo "RABBIT_ENABLED=false" >> $GITHUB_ENV
                      echo "KAFKA_ENABLED=true" >> $GITHUB_ENV
                      ;;
                  *)
                      echo $"Unsupported broker: $INPUT_BROKER"
                      exit 1
          esac

          echo BROKER=${INPUT_BROKER:rabbit} >> $GITHUB_ENV
      # setup common tooling
      # we need tmc and helm
      - name: Install tooling
        run: |
         curl -sLO https://tmc-cli.s3-us-west-2.amazonaws.com/tmc/latest/linux/x64/tmc
         chmod +x tmc
         sudo mv tmc /usr/local/bin/
         curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3
         chmod 700 get_helm.sh
         ./get_helm.sh

      # install kubectl
      - uses: azure/setup-kubectl@v1

      # configure tmc
      # just common login and context conf
      # tmc token is set to one from jannev as we don't have machine user
      - name: Configure tmc
        env:
         TMC_API_TOKEN: ${{ secrets.TMC_API_TOKEN }}
        run: |
         tmc login --name dummy --no-configure
         tmc configure --management-cluster-name aws-hosted --provisioner-name scdf-provisioner
      # checkout repos
      # scdf-k8s-packaging dataflow deploy, private repo so needs gh pat to checkout
      - uses: actions/checkout@v2
        with:
         path: scdf
      # generate cluster name
      # we use date to get semi random string as /dev/urandom may block for real random
      - name: Generate cluster name
        run: |
         echo CLUSTER_NAME=scdf-helm-at-$(date +%s%N) >> $GITHUB_ENV

      # create cluster
      # use template file and change it name to generated cluster name
      - name: Create cluster
        run: |
         sed -i 's/name-changeme/'"$CLUSTER_NAME"'/g' scdf/.github/tmc/tmc-template.yaml
         sed -i 's/version-changeme/'"$K8S"'/g' scdf/.github/tmc/tmc-template.yaml
         tmc cluster create -f scdf/.github/tmc/tmc-template.yaml

      # wait cluster
      # trick is to request kubeconfig as tmc errors until things are actually up and running
      # do it once more to fail step if timeout
      - name: Wait cluster
        run: |
          echo waiting tmc to give kube config
          for i in $(seq 40)
          do
            (tmc cluster auth kubeconfig get $CLUSTER_NAME > /dev/null 2>&1) && break || echo "waiting cluster $i/40 ..."
            sleep 30
          done
          tmc cluster auth kubeconfig get $CLUSTER_NAME > /dev/null

      # setting up kubeconfig for access
      # well that's great, test scripts needs to have KUBECONFIG so point to default config
      - name: Setup kube access
        run: |
          mkdir -p $HOME/.kube
          tmc cluster auth kubeconfig get $CLUSTER_NAME > $HOME/.kube/config
          echo KUBECONFIG=$HOME/.kube/config >> $GITHUB_ENV

      # tweak settings
      # come up without having scdf-image-regcred secret
      # we also need to relax privileges as skipper/dataflow containers expects root
      - name: Tweak settings
        env:
          DOCKER_HUB_USERNAME: ${{ secrets.DOCKER_HUB_USERNAME }}
          DOCKER_HUB_PASSWORD: ${{ secrets.DOCKER_HUB_PASSWORD }}
        run: |
          kubectl create rolebinding rolebinding-default-privileged-sa-ns_default \
            --namespace default \
            --clusterrole=vmware-system-tmc-psp-privileged \
            --user=system:serviceaccount:default:default
          kubectl create clusterrolebinding default-privileged-cluster-role-binding \
            --clusterrole=vmware-system-tmc-psp-privileged \
            --group=system:authenticated
          kubectl create secret docker-registry scdf-metadata-default \
            --docker-username=$DOCKER_HUB_USERNAME \
            --docker-password=$DOCKER_HUB_PASSWORD

      - name: Install SCDF helm chart
        run: |
            helm repo add bitnami https://charts.bitnami.com/bitnami
            helm install my-release bitnami/spring-cloud-dataflow --set rabbit.enabled=$RABBIT_ENABLED --set kafka.enabled=$KAFKA_ENABLED
      # print cluster info
      - name: Cluster info
        run: |
          kubectl get all
